{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Welcome!\n",
    "\n",
    "The goal for today is to introduce data analysis through an applied project. Given the variety in experience in this group, three options are available for you:\n",
    "\n",
    "1. Beginner: We will work through this file together, line by line, as I explain reasoning and answer questions as we go along.\n",
    "2. Experienced: You independently work through `appointments_skeleton.ipynb`,  a file similar to this one but without the answers. \n",
    "3. Independent: Using the MIMIC2 ICU data, predict mortality or length of stay (https://www.kaggle.com/drscarlat/mimic2-original-icu/version/1).\n",
    "\n",
    "We will reconvene as a group at 7:30 and share what each one did, debrief on learnings, and answer any remaining questions.\n",
    "\n",
    "Choose your adventure!\n",
    "\n",
    "------\n",
    "\n",
    "## Missed Appointments\n",
    "\n",
    "A clinic is in trouble, as they have been wasting resources every month when staff is available but rooms are empty. We have been tasked with understanding why people who receive treatment instructions do not show up at the next appointment time. How often are patients missing appointments? Who is missing most often? What are the contributing factors for missing appointments?\n",
    "\n",
    "This example is based on a Kaggle dataset and strongly inspired by Veronika Rovnik's blog post.\n",
    "\n",
    "Blog: https://towardsdatascience.com/exploratory-analysis-python-kaggle-data-b0afb6ec1788\n",
    "\n",
    "Data: https://www.kaggle.com/joniarroba/noshowappointments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set up\n",
    "We start by importing the main libraries we will use. The big one for data munging is `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# For data processing:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# For plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# For modeling:\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Read in data\n",
    "After you’ve downloaded the data from Kaggle, the next step is to build a pandas DataFrame based on the CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df = pd.read_csv('KaggleV2-May-2016.csv')\n",
    "# Naming your data \"df\" is common practice, and you will see many examples do that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Profile the data\n",
    "Before cleaning the data, let’s check the overall quality of the data and data types of each column.\n",
    "What columns does the data have? How many patients are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(\"Number of records (patients): \", df.shape[0])\n",
    "print(\"Number of columns (features): \", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In our analysis, what is the primary ouotcome, or the characteristic of interest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The columns are called \"features\" of the data. They are also called \"covariates\", \"predictors\", or even \"correlates\". These are the characteristics we will use to estimate our primary outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Fix the column names\n",
    "You may have noticed that our features contain typing errors.\n",
    "Let’s rename misspelled column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df = df.rename(columns={'Hipertension': 'Hypertension', 'SMS_received': 'SMSReceived'})\n",
    "df.head()\n",
    "# There's another column that is misspelled. Rename that one too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cleaning & preparing the data content\n",
    "Cleaning the data is an art that should be mastered in the first place before starting any data science or machine learning project. It makes data easier to investigate and build visualizations. Through this process you will also start to \"get to know\" your data, and therefore understand how to best levarage it during modeling.\n",
    "\n",
    "\n",
    "After you’ve checked the data types of features, you may have noticed that `ScheduledDay` and `AppointmentDay` features have an `object` data type.\n",
    "To make dealing with date features easies, let’s convert the type of ‘ScheduledDay’ and ‘AppointmentDay’ to `datetime64[ns]`. You need this to get access to useful methods and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay']).dt.date.astype('datetime64[ns]')\n",
    "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay']).dt.date.astype('datetime64[ns]')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also rename “No-show” column to “Presence” and its values to ‘Present’ and ‘Absent’ so as to avoid any misinterpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# First we create a new column, as a function of the No-show column.\n",
    "df['Presence'] = df['No-show'].apply(lambda x: 'Present' if x == \"No\" else 'Absent')\n",
    "# We can now remove the No-show column.\n",
    "df = df.drop('No-show',axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature engineering\n",
    "Now that the data we have is neatly organized, let's go back to our goal: To understand why people who receive treatment instructions do not show up at the next appointment time. In other words, what are the contributing factors for missing appointments?\n",
    "\n",
    "Given this goal, we ask ourselves: is there something we can calculate from what we have that will help us more directly answer the question? This is called _feature engineering_. Feature engineering refers to the process of using domain knowledge to select and transform the most relevant variables from raw data when creating a predictive model using machine learning or statistical modeling.\n",
    "\n",
    "In this case, we have the date the appointment was scheduled and the date of the actual appointment, but what may be helpful is the **time** between these two. So, we can add a new feature to the dataset — ‘Waiting Time Days’ to note how long the patient needs to wait for the appointment day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df['WaitingTimeDays'] = df['AppointmentDay'] - df['ScheduledDay']\n",
    "df['WaitingTimeDays'] = df['WaitingTimeDays'].dt.days\n",
    "# Can also be done in a single line:\n",
    "#df['WaitingTimeDays'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We could also believe that the day of the week may matter. Let's add that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df['WeekDay'] = df['AppointmentDay'].apply(lambda x: x.weekday())\n",
    "replace_map = {'WeekDay': {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday'}}\n",
    "df.replace(replace_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# A quick sanity check the resulting variable:\n",
    "df[\"WeekDay\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"Feature engineering\" may sound boring and inconsequential, but it is actually an essential step in any analysis. On a per-hour (and certainly per-computation), it is orders of magnitude more impactful than model parameter tuning. Also note that the term feature engineering is mostly used in macchine learning. In other fields it is just a part of the \"data wrangling\" or \"data preparation\" process.\n",
    "\n",
    "Here is a great article with more details and examples: https://medium.com/@mortenjorgensen_16022/feature-engineering-the-secret-sauce-to-applied-machine-learning-e61ac5963405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check for Missing Data\n",
    "\n",
    "Before going any further, let’s see if there are null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are lucky (and rather unrealistic) — there are no null values in our dataset! \n",
    "\n",
    "What would we have done if there were missing values? What effect would that choice have had in our future conclusions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploratory Analysis\n",
    "We can now get a bit deeper into each variable (or feature) and see what kind of patients we have.\n",
    "\n",
    "For numeric variables we can get a quick sense of what's happening with a table showing numeric summaries for each.\n",
    "_What 3 things can you learn about the data from this table?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For categorical variables, we can count the number in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df[\"Presence\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is helpful, but we care more about the relative counts (percentages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# We can get the proportion by adding `normalize=True`\n",
    "df[\"Presence\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df[\"Neighbourhood\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df[\"Gender\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also make a bar plot of Presence: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "counts = df.groupby('Presence').count()[['AppointmentID']].reset_index()\n",
    "counts\n",
    "# Let's use a simple bar chart in Seaborn to compare counts for the two drugs\n",
    "# There are several different ways to do the plotting - this is my preferred style,\n",
    "# but you might prefer different syntax\n",
    "fig = sns.barplot(data=counts, x='Presence', y='AppointmentID')\n",
    "plt.title('Number of appointments by Presence')\n",
    "plt.ylabel('Number of appointments')\n",
    "plt.xlabel('Presence')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Analysis\n",
    "We now get into some variable relationships. Remember our question: who is missing appointments?\n",
    "\n",
    "Let's look at the weekday variable we created. Are people more likely to miss an appointment on certain days?\n",
    "\n",
    "Which day has the most missed appointments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "df_absent = df[df['Presence']==\"Absent\"]\n",
    "counts = df_absent.groupby('WeekDay').count()[['AppointmentID']].reset_index()\n",
    "counts\n",
    "# Let's use a simple bar chart in Seaborn to compare counts for the two drugs\n",
    "# There are several different ways to do the plotting - this is my preferred style,\n",
    "# but you might prefer different syntax\n",
    "fig = sns.barplot(data=counts, x='WeekDay', y='AppointmentID')\n",
    "plt.title('Number of absent appointments by day of week')\n",
    "plt.ylabel('Number of appointments')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What can we learn from this plot?\n",
    "We see that Saturday and Thursday have the two fewest missed appointments. Does that mean that Saturday patients are the most compliant?\n",
    "\n",
    "Let's look at the data a different way, as a table of proportion of missed appointments by day oof week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "pd.crosstab(index=df['WeekDay'], columns=df['Presence'], normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What does the table tell us? Do you prefer the table or the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "While the barplot above is not \"wrong\", it does not answer the question we have, and can actually be misleading. What would be a better barplot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x, y, hue = \"Presence\", \"proportion\", \"WeekDay\"\n",
    "hue_order = [\"0\", \"1\"]\n",
    "\n",
    "(df[x]\n",
    " .groupby(df[hue])\n",
    " .value_counts(normalize=True)\n",
    " .rename(y)\n",
    " .reset_index()\n",
    " .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x, y, hue = \"WeekDay\", \"proportion\", \"Presence\"\n",
    "hue_order = [\"0\", \"1\"]\n",
    "\n",
    "(df[x]\n",
    " .groupby(df[hue])\n",
    " .value_counts(normalize=True)\n",
    " .rename(y)\n",
    " .reset_index()\n",
    " .pipe((sns.barplot, \"data\"), x=x, y=y, hue=hue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Take 5 minutes and decide two more plots you'd like to make with this dataset to get to know it better. You do not have to actually code them (unless you want). The act of thinking through what would be helpful is crucial, and is often overlooked, and we get caught up in the joy of coding.\n",
    "\n",
    "\n",
    "\n",
    "_One plot would be ..._\n",
    "_Another plot would be ..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model\n",
    "\n",
    "Ok! So now we have a sense of the data available, and in broad stokes what is going on.\n",
    "\n",
    "Let's return to our question. A helpful technique to go from a business or scientific question to something we can create a model for is to rephrase our question probabilistically. In this case we could ask: _what is the expected probability patient A will miss the next an appointment?_\n",
    "\n",
    "To start, let's say we know nothing else about the patient. What is our best guess of this probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_The best guess is the overall proportion of patients who missed an appointment, 20%_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, I tell you that the appointment is scheduled for a Saturday. Do you update your guess?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_Yes, now my guess is the overall average for Saturday appointments, which is 23%_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, I tell you that the patient is female, and all sorts of other characteristics. How would you update your guess now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_With several characteristics, we can't use contingency tables and instead move to statistical models, or use machines to do our learning :)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Decision Tree\n",
    "\n",
    "One very powerful model is a `decision tree`. This framework is useful for non-linear relationships between features, when a regression may not be flexible enough. It also produces a very explainable model.\n",
    "\n",
    "Great summary of trees and figures: https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Start by creating `X`, a subset of `df` with the *predictors* to use. Also create Y, with only the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "X = df[[\n",
    "        #'Gender',\n",
    " 'Age',\n",
    " #'Neighbourhood',\n",
    " 'Scholarship',\n",
    " 'Hypertension',\n",
    " 'Diabetes',\n",
    " 'Alcoholism',\n",
    " 'Handcap',\n",
    " 'SMSReceived',\n",
    " 'WaitingTimeDays'#,\n",
    "# 'WeekDay'\n",
    "    ]]\n",
    "y = df['Presence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Now, instantiate the tree and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# Instantiate model object\n",
    "clf = DecisionTreeClassifier(random_state=0,max_depth=5)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Fit it to our data\n",
    "mod_tree = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "mod_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "How can we summarize how well our model worked? Since we are classifying into categories, calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Predict on same data\n",
    "preds = mod_tree.predict(X)\n",
    "# Create manual \"confusion matrix\"\n",
    "df_wpred = df.copy()\n",
    "df_wpred['pred'] = preds\n",
    "#pd.crosstab(index=df_wpred['pred'], columns=df_wpred['Presence'], normalize='index')\n",
    "#pd.crosstab(index=df_wpred['pred'], columns=df_wpred['Presence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Of course, there's an automatic way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Accuracy\n",
    "mod_tree.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "(9497+84152)/(9497+84152+4056+12822)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Is this a good, excellent, or poor accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "How can we improve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Some may have noticed that we did not use all of the features in our dataset. Which did we leave out?\n",
    "\n",
    "The tree model _only_ takes numeric variables. So what do we do with something like Weekday? Well, in order to use the categorical variables, we need to transform them into numeric.\n",
    "\n",
    "The way we do this is by making dummy variables, also known as one-hoot-encoding. Do this for Gender, and WeekDay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Change the class from \"object\" to categorical\n",
    "for col in ['Gender','WeekDay', 'Neighbourhood']:\n",
    "    df[col] = df[col].astype('category')\n",
    "# add dummy variables  \n",
    "df = pd.get_dummies(data=df,columns=['Gender','WeekDay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's fit a second model with these features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "X_2 = df[[\n",
    "  'Gender_F',\n",
    "  'Gender_M',\n",
    " 'Age',\n",
    " #'Neighbourhood',\n",
    " 'Scholarship',\n",
    " 'Hypertension',\n",
    " 'Diabetes',\n",
    " 'Alcoholism',\n",
    " 'Handcap',\n",
    " 'SMSReceived',\n",
    " 'WaitingTimeDays',\n",
    " 'WeekDay_Monday',\n",
    " 'WeekDay_Tuesday',\n",
    " 'WeekDay_Wednesday',\n",
    " 'WeekDay_Thursday',\n",
    " 'WeekDay_Friday',\n",
    " 'WeekDay_Saturday'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "clf_2 = DecisionTreeClassifier(random_state=0,max_depth=5)\n",
    "mod_tree_2= clf_2.fit(X_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "mod_tree_2.score(X_2,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "mod_tree_2.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Take a look at the tree using a text representation. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "text_representation = tree.export_text(clf_2)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One important way to understand the model is with the *variable importance*. Although different models calculate it slightly differently, the idea is to rank features according to how useful they are in the prediction.\n",
    "\n",
    "Let's find it for our tree. Were all features helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "importance = mod_tree_2.feature_importances_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Put importance in a dataframe to make it readable\n",
    "importance_dat = {'Var':mod_tree_2.feature_names_in_,\n",
    "                  'Importance':importance}\n",
    "importance_dat = pd.DataFrame(importance_dat)\n",
    "print(importance_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's fit a model with only the top most important variables. Does our accuracy change much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "X_3 = df[[\n",
    " 'Age',\n",
    " 'WaitingTimeDays'\n",
    "    ]]\n",
    "clf_3 = DecisionTreeClassifier(random_state=0, max_depth=5)\n",
    "mod_tree_3 = clf_3.fit(X_3, y)\n",
    "mod_tree_3.score(X_3,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pick one of the top variables, and make a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Boxplot of WaitingTimeDays by wheter appoointment was missed.\n",
    "\n",
    "days_abs = df[df['Presence']==\"Absent\"][\"WaitingTimeDays\"]\n",
    "days_pre = df[df['Presence']==\"Present\"][\"WaitingTimeDays\"]\n",
    "\n",
    "data = [days_abs, days_pre]\n",
    "\n",
    "fig = plt.figure(figsize =(3, 4))\n",
    "\n",
    "# Creating axes instance\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "# x-axis labels\n",
    "ax.set_xticklabels(['Absent', 'Present'])\n",
    "\n",
    "# Creating plot\n",
    "bp = ax.boxplot(data)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "text_representation = tree.export_text(clf_3)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Other tree visualizations: https://towardsdatascience.com/visualizing-decision-trees-with-python-scikit-learn-graphviz-matplotlib-1c50b4aa68dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### What about SMS?\n",
    "\n",
    "This clinic has been trying to mitigate this problem, and started sending SMS (text messages) to some of its patients. Did that effort work? In this analysis it was not one of the most important variables. Does that mean they should stop? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extensions\n",
    "Another model we can use when we have only two variables is logistic regression. This is a very powerful model when we have smaller data, and produces interpretable results. Beware that the default implementation is a _penalized_ logistic regression.\n",
    "\n",
    "For any model, we will similarly look at accuracy, and variable importance. Other metrics such as recall and precision (or sensitivity and specificity) can be quite useful.\n",
    "\n",
    "One aspect we did not cover here is cross validation. In reality, we would want to make sure we train the model with one subset of the data, and test the accuracy of another. Otherwise, we are very likely to over-fit and get a high accuracy that is not actually representative of how the model would perform with new data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Wrap up\n",
    "\n",
    "This was only a glimpse into what we could do in an analysis of this dataset. If you'd like to see other analyses, go to the Kaggle repository ( https://www.kaggle.com/joniarroba/noshowappointments/code)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}